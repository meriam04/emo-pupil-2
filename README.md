# Emotion Watchers

Hi! Welcome to the Emotion Watchers GitHub page! 

We are Divya, Meriam, Kirti and Colin â€” 4th year engineering students at the University of Toronto and this is our capstone project!

PUT IMAGE HERE

This project continues the research of EmoPupil, which was also conducted under the supervision of Professor Hatzinakos.
 
This project will build upon EmoPupil, which involves using pupillometry to analyze internal emotions ðŸ‘€

In addition to pupillometry, this project will interpret facial expressions from images for emotion classification ðŸ˜„

An AI model can make more inferences given more data, therefore fusing these modalities will result in better performance and reliability, beyond EmoPupil or other conventional projects ðŸ˜„ + ðŸ‘€ = ðŸ’»


Project Goal:
The objective of this project is to develop an emotion detection system, with both face and pupillometry modalities, which performs comparably to EmoPupil in prediction accuracy 


The following is a breakdown of our project:

                                             ![image](https://github.com/meriam04/emotion-watchers/assets/90280208/c3cebe10-f839-4b4d-b3e7-8d42d9b710aa)


                                              ![image](https://github.com/meriam04/emotion-watchers/assets/90280208/d7cfe8c8-c2d6-445a-bfca-b15a92ba3c30)



























![visitors](https://visitor-badge.glitch.me/badge?page_id=page.id)
